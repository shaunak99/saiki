# describes the mcp servers to use
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .
  playwright:
    type: stdio
    command: npx
    args:
      - -y
      - "@playwright/mcp@latest"

# System prompt configuration - defines the agent's behavior and instructions
systemPrompt:
  contributors:
    - id: primary
      type: static
      priority: 0
      content: |
        You are a helpful AI assistant with access to tools.
        Use these tools when appropriate to answer user queries.
        You can use multiple tools in sequence to solve complex problems.
        After each tool result, determine if you need more information or can provide a final answer.
    - id: dateTime
      type: dynamic
      priority: 10
      source: dateTime
      enabled: true

# Optional greeting shown at chat start (UI can consume this)
greeting: "Hi! I‚Äôm Dexto ‚Äî how can I help today?"

# LLM configuration - describes the language model to use
llm:
  provider: openai
  model: gpt-5-mini
  apiKey: $OPENAI_API_KEY

storage:
  cache:
    type: in-memory
  database:
    type: sqlite
    # path: ./data/dexto.db  # Optional: customize database location

toolConfirmation:
  mode: event-based
  timeout: 120000          # Time to wait for approval (ms)
  allowedToolsStorage: memory  # 'memory' or 'storage' for persisting allowed tools

# Internal resources configuration - manages file system access and blob storage
# NOTE: Blob storage capacity and backend settings are in the 'blobStorage' section below
internalResources:
  enabled: true
  resources:
    # Filesystem resource - provides read access to local files for the agent
    - type: filesystem
      paths: ["."]                 # Directories to expose
      maxFiles: 50               # Maximum number of files to index
      maxDepth: 3                # Maximum directory depth to traverse
      includeHidden: false         # Include hidden files/directories
      includeExtensions: [".txt", ".md", ".json", ".yaml", ".yml", ".js", ".ts", ".py", ".html", ".css"]

    # Blob resource - enables large file upload/storage (settings in blobStorage section)
    - type: blob

# Starter prompts - predefined prompts that appear as clickable buttons in the WebUI
starterPrompts:
  - id: quick-start
    title: "Quick Start Guide"
    description: "Learn the basics and see what you can do"
    prompt: "I'd like to get started quickly. Can you show me a few examples of what you can do and help me understand how to work with you?"
    category: learning
    icon: "üìö"
    priority: 9
  - id: tool-demo
    title: "Tool Demonstration"
    description: "See the tools in action with practical examples"
    prompt: "I'd like to see your tools in action. Can you pick one of your most interesting tools and demonstrate it with a practical example? Show me what it can do and how it works."
    category: tools
    icon: "‚ö°"
    priority: 5
  - id: snake-game
    title: "Create Snake Game"
    description: "Build a fun interactive game with HTML, CSS, and JavaScript"
    prompt: "Create a snake game in a new directory with HTML, CSS, and JavaScript, then open it in the browser for me to play."
    category: coding
    icon: "üêç"
    priority: 4
  - id: connect-tools
    title: "Connect New Tools"
    description: "Browse and add MCP servers to extend capabilities"
    prompt: "I want to connect new tools to expand my capabilities. Can you help me understand what MCP servers are available and how to add them?"
    category: tools
    icon: "üîß"
    priority: 3

# Blob storage configuration - infrastructure-level storage for large files
# This section controls the actual blob backend, size limits, and cleanup policies
blobStorage:
  type: local  # 'local', 's3', 'gcs', 'azure' (s3, gcs, azure coming in future Phases)
  maxBlobSize: 52428800     # 50MB per blob
  maxTotalSize: 1073741824  # 1GB total storage
  cleanupAfterDays: 30      # Auto-cleanup blobs older than 30 days
  # storePath: ~/.dexto/blobs (defaults to context-aware path for local backend)

## To use Google Gemini, replace the LLM section with Google Gemini configuration below
## Similar for anthropic/groq/etc.
# llm:
#   provider: google
#   model: gemini-2.5-pro
#   apiKey: $GOOGLE_GENERATIVE_AI_API_KEY
